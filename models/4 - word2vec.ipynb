{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Word2Vec é um modelo de aprendizado de máquina criado pelo Google (Mikolov et al., 2013) que aprende representações vetoriais densas de palavras, chamadas de word embeddings.\n",
        "\n",
        "Cada palavra é mapeada para um vetor de números reais (ex: 100 ou 300 dimensões), e a distância entre vetores reflete a similaridade semântica entre as palavras.\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "vetor(\"rei\") - vetor(\"homem\") + vetor(\"mulher\") ≈ vetor(\"rainha\")\n",
        "\n",
        "Word2Vec é treinado em grandes coleções de texto e tenta prever relações entre palavras vizinhas.\n",
        "Existem duas arquiteturas principais:\n",
        "\n",
        "1) CBOW (Continuous Bag of Words)\n",
        "\n",
        "Prediz a palavra central com base nas palavras de contexto ao redor.\n",
        "Exemplo:\n",
        "\n",
        "Contexto: “o gato está no” → Modelo tenta prever “sofá”.\n",
        "\n",
        "2) Skip-Gram\n",
        "\n",
        "Faz o inverso: usa uma palavra central para prever as palavras do contexto.\n",
        "Exemplo:\n",
        "\n",
        "Palavra central: “gato” → Modelo tenta prever “o”, “está”, “no”, “sofá”.\n",
        "\n",
        "| Modelo        | Entrada            | Saída               | Ideal para |\n",
        "| ------------- | ------------------ | ------------------- | ---------- |\n",
        "| **CBOW**      | Contexto → Palavra | Palavras frequentes |            |\n",
        "| **Skip-Gram** | Palavra → Contexto | Palavras raras      |            |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GmKbOvTO7HRC",
        "outputId": "5aec0135-8c27-4ec5-861e-ea7818a8d1d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in c:\\users\\luirys silva\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\luirys silva\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (2.3.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\luirys silva\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\luirys silva\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.4.4)\n",
            "Requirement already satisfied: wrapt in c:\\users\\luirys silva\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Gensim é conhecido por sua implementação eficiente do modelo Word2Vec.\n",
        "# Ele permite treinar modelos de representação de palavras usando grandes\n",
        "# conjuntos de dados textuais.\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z3uDqv4u1xYl",
        "outputId": "98c89b6b-b8ef-4aaa-e2d9-13f473d2640a"
      },
      "outputs": [],
      "source": [
        "#Atualiza numpy e gensim sem cache (força download do mais recente)\n",
        "#Reinicia automaticamente o ambiente do Colab (necessário para atualizar dependências)\n",
        "!pip install --upgrade numpy gensim --no-cache-dir\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPa8yhz57Zs1"
      },
      "source": [
        "### Repositório de Vetores Treinados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSq63dQ8Gka"
      },
      "source": [
        "Os repositórios trazem vetores gerados a partir de um grande córpus do português do Brasil e português europeu, de fontes e gêneros variados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47HlfZZZ8Pps",
        "outputId": "e30628fe-62d5-4a2e-ae5f-360e66e0f696"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(453, 1290)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Corpus de texto\n",
        "#corpus = [\n",
        "#    \"No meio do caminho tinha uma pedra\",\n",
        "#    \"Tinha uma pedra no meio do caminho\",\n",
        "#    \"Tinha uma pedra no meio do caminho\",\n",
        "#    \"Tinha uma pedra\",\n",
        "#    \"Nunca me esquecerei desse acontecimento\",\n",
        "#    \"Na vida de minhas retinas tão fatigadas\",\n",
        "#    \"Nunca me esquecerei\",\n",
        "#    \"Que no meio do caminho tinha uma pedra\",\n",
        "#    \"Tinha uma pedra no meio do caminho\",\n",
        "#    \"No meio do caminho tinha uma pedra\"\n",
        "#]\n",
        "\n",
        "corpus = [\n",
        "    \"A sustentabilidade é um tema central para o futuro do planeta.\",\n",
        "    \"Empresas têm investido cada vez mais em energia renovável para reduzir o impacto ambiental.\",\n",
        "    \"O consumo consciente pode mudar o mundo.\",\n",
        "    \"Governos ao redor do mundo discutem políticas para mitigar os efeitos das mudanças climáticas.\",\n",
        "    \"A preservação da biodiversidade é fundamental para o equilíbrio do ecossistema.\",\n",
        "    \"A reciclagem é uma das formas mais simples de ajudar o meio ambiente.\",\n",
        "    \"Projetos de energia solar têm crescido exponencialmente nos últimos anos.\",\n",
        "    \"É urgente a transição para uma economia de baixo carbono.\",\n",
        "    \"As ações para preservar os oceanos são essenciais para combater a poluição por plástico.\",\n",
        "    \"A educação ambiental é a chave para conscientizar a sociedade sobre a importância da sustentabilidade.\"\n",
        "]\n",
        "\n",
        "# Tokenização das sentenças\n",
        "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]\n",
        "\n",
        "# Treinamento do modelo Word2Vec\n",
        "# sentences: A lista de sentenças tokenizadas.\n",
        "# vector_size: A dimensão dos vetores de palavra.\n",
        "# window: O número máximo de palavras entre a palavra-alvo e as palavras ao seu redor.\n",
        "# sg=0 CBOW, sg=1 SKIP-GRAM\n",
        "# min_count: Ignora todas as palavras com frequência total inferior a esse valor.\n",
        "# workers: O número de threads de treinamento paralelo para acelerar o treinamento.\n",
        "model = Word2Vec(sentences=tokenized_corpus, vector_size=3, window=5, sg=0, min_count=1, workers=4)\n",
        "\n",
        "# Salvando o modelo\n",
        "model.save(\"word2vec_model\")\n",
        "\n",
        "#Treinando o modelo\n",
        "# Treinamento do modelo\n",
        "model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=10)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LHmbPltemcT",
        "outputId": "3de66b4e-5491-4d38-edbb-2dc2ad40cf0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor da palavra 'sustentabilidade': [-0.01284751 -0.25813052  0.33164984]\n",
            "Distância entre sustentabilidade e mundo  0.4883633\n",
            "Distância entre mundo e sustentabilidade  0.4883633\n",
            "Distância entre sustentabilidade e energia  0.22549395\n",
            "Distância entre mundo e energia  0.3480273\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de como obter o vetor de uma palavra\n",
        "sustentabilidade = model.wv['sustentabilidade']\n",
        "mundo = model.wv['mundo']\n",
        "energia = model.wv['energia']\n",
        "\n",
        "print(\"Vetor da palavra 'sustentabilidade':\", sustentabilidade)\n",
        "\n",
        "def dist_euclidiana(u,v):\n",
        "  return np.linalg.norm(u - v)\n",
        "\n",
        "#Imprimindo os caminhos\n",
        "d1 = dist_euclidiana(sustentabilidade,mundo)\n",
        "d2 = dist_euclidiana(mundo,sustentabilidade)\n",
        "d3 = dist_euclidiana(sustentabilidade,energia)\n",
        "d4 = dist_euclidiana(mundo,energia)\n",
        "\n",
        "print(\"Distância entre sustentabilidade e mundo \", d1)\n",
        "print(\"Distância entre mundo e sustentabilidade \", d2)\n",
        "print(\"Distância entre sustentabilidade e energia \", d3)\n",
        "print(\"Distância entre mundo e energia \", d4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLiYw-ZFm8Ur",
        "outputId": "e994ac6f-d058-418c-fe2e-ec06fb01a49b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distância entre sustentabilidade e mundo  0.036659546\n",
            "Distância entre mundo e sustentabilidade  0.036659546\n",
            "Distância entre sustentabilidade e energia  0.8504076\n",
            "Distância entre mundo e energia  0.51744974\n"
          ]
        }
      ],
      "source": [
        "def similaridade_cossenos(u,v):\n",
        "  return np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v))\n",
        "\n",
        "s1 = similaridade_cossenos(sustentabilidade,mundo)\n",
        "s2 = similaridade_cossenos(mundo,sustentabilidade)\n",
        "s3 = similaridade_cossenos(sustentabilidade,energia)\n",
        "s4 = similaridade_cossenos(mundo,energia)\n",
        "\n",
        "print(\"Distância entre sustentabilidade e mundo \", s1)\n",
        "print(\"Distância entre mundo e sustentabilidade \", s2)\n",
        "print(\"Distância entre sustentabilidade e energia \", s3)\n",
        "print(\"Distância entre mundo e energia \", s4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVfN4JzDqrh8",
        "outputId": "65e99cb9-e3f5-43f0-e8ca-5ee9f7193de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('mundo', 0.9682457447052002), ('exponencialmente', 0.8894082307815552), ('crescido', 0.8879284858703613), ('anos', 0.8688837885856628), ('das', 0.8634596467018127), ('economia', 0.8627527356147766), ('sobre', 0.8446546196937561), ('consciente', 0.7998927235603333), ('últimos', 0.7663198709487915), ('as', 0.7554173469543457)]\n",
            "[('energia', 0.9999999403953552), ('do', 0.9702626466751099), ('poluição', 0.9681754112243652), ('ambiente', 0.9654175639152527), ('tema', 0.9628732204437256), ('essenciais', 0.94303959608078), ('urgente', 0.8962976932525635), ('mudanças', 0.8893173336982727), ('reduzir', 0.8885645866394043), ('as', 0.8789161443710327), ('ao', 0.8566858172416687), ('consciente', 0.8508978486061096), ('sustentabilidade', 0.8504075407981873), ('mudar', 0.8313300013542175), ('efeitos', 0.7987024784088135)]\n"
          ]
        }
      ],
      "source": [
        "#Analogia\n",
        "\n",
        "# Exemplo\n",
        "# x1= mulher, x2=homem, y1=rei, y2 = ?\n",
        "# Mulher - Homem = y2 - Rei\n",
        "# y2 = Mulher - Homem + Rei\n",
        "# positives: Mulher e Rei\n",
        "# Negative: Homem\n",
        "def analogia(x1,x2,y1):\n",
        "  y2 = model.wv.most_similar(positive = [x1, y1], negative = [x2])\n",
        "  return y2\n",
        "\n",
        "print(analogia(mundo, sustentabilidade, energia))\n",
        "\n",
        "# Usando wv.most_similar\n",
        "# No caso do CBOW, você obtém palavras similares à palavra-chave, e no caso do Skip-gram,\n",
        "# você obtém palavras contextuais para a palavra-chave fornecida.\n",
        "similar_words = model.wv.most_similar(energia, topn=15)\n",
        "print(similar_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
